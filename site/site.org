#+OPTIONS: ':nil -:nil ^:{} num:nil toc:nil
#+AUTHOR: Hiroyuki Yamada
#+CREATOR: Emacs 26.1 (Org mode 9.1.14 + ox-hugo)
#+HUGO_WITH_LOCALE:
#+HUGO_FRONT_MATTER_FORMAT: toml
#+HUGO_LEVEL_OFFSET: 1
#+HUGO_PRESERVE_FILLING:
#+HUGO_DELETE_TRAILING_WS:
#+HUGO_SECTION: .
#+HUGO_BUNDLE:
#+HUGO_BASE_DIR: ./
#+HUGO_CODE_FENCE:
#+HUGO_USE_CODE_FOR_KBD:
#+HUGO_PREFER_HYPHEN_IN_TAGS:
#+HUGO_ALLOW_SPACES_IN_TAGS:
#+HUGO_AUTO_SET_LASTMOD:
#+HUGO_CUSTOM_FRONT_MATTER:
#+HUGO_BLACKFRIDAY:
#+HUGO_FRONT_MATTER_KEY_REPLACE:
#+HUGO_DATE_FORMAT: %Y-%m-%dT%T+09:00
#+HUGO_PAIRED_SHORTCODES:
#+HUGO_PANDOC_CITATIONS:
#+BIBLIOGRAPHY:
#+HUGO_ALIASES:
#+HUGO_AUDIO:
#+DATE: <2019-02-10 Sun>
#+DESCRIPTION:
#+HUGO_DRAFT:
#+HUGO_EXPIRYDATE:
#+HUGO_HEADLESS:
#+HUGO_IMAGES:
#+HUGO_ISCJKLANGUAGE:
#+KEYWORDS:
#+HUGO_LAYOUT:
#+HUGO_LASTMOD:
#+HUGO_LINKTITLE:
#+HUGO_LOCALE:
#+HUGO_MARKUP:
#+HUGO_MENU:
#+HUGO_MENU_OVERRIDE:
#+HUGO_OUTPUTS:
#+HUGO_PUBLISHDATE:
#+HUGO_SERIES:
#+HUGO_SLUG:
#+HUGO_TAGS:
#+HUGO_CATEGORIES:
#+HUGO_RESOURCES:
#+HUGO_TYPE:
#+HUGO_URL:
#+HUGO_VIDEOS:
#+HUGO_WEIGHT: auto

#+STARTUP: showall logdone
* DONE cpprb (C++ Replay Buffer)
CLOSED: [2019-02-10 Sun 20:24]
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_SECTION: .
:END:

** cpprb (C++ Replay Buffer)
~cpprb~ is a python package written by C++. The package provides
replay buffer classes for reinforcement learning.

* Features
:PROPERTIES:
:EXPORT_HUGO_SECTION*: features
:END:

** DONE Flexible Environment
CLOSED: [2019-11-08 Fri 05:58]
:PROPERTIES:
:EXPORT_FILE_NAME: flexible_environment
:END:

*** Overview

In ~cpprb~ version 8 and newer, you can store any number of
environments (aka. observation, action, etc.).

For example, you can add your special environments like
~next_next_obs~, ~second_reward~, and so on.

These environments can take multi-dimensional shape (e.g. ~3~,
~(4,4)~, ~(84,84,4)~), and any [[https://numpy.org/devdocs/user/basics.types.html][numpy data type]].


**** ~__init__~
In order to construct replay buffers, you need to specify the second
parameter of their constructor, ~env_dict~.

The ~env_dict~ is a ~dict~ whose keys are environment name and whose
values are ~dict~ describing their properties.

The following table is supported properties and their default values.

| key   | description                    | type                         | default value                                    |
|-------+--------------------------------+------------------------------+--------------------------------------------------|
| shape | shape (size of each dimension) | ~int~ or array like of ~int~ | ~1~                                              |
| dtype | data type                      | ~numpy.dtype~                | ~default_dtype~ in constructor or ~numpy.single~ |

**** ~add~
When ~add~ -ing environments to the replay buffer, you have to pass
them by keyword arguments (aka. ~key=value~ style). If your
environment name is not a syntactically valid identifier, you can
still create dictionary first, then unpack the dictionary by ~**~
operator (e.g. ~rb.add(**kwargs)~).

**** ~sample~
~sample~ returns ~dict~ with keys of environments' name and with
values of sampled ones.


*** Example Usage

#+begin_src python
from cpprb import ReplayBuffer
import numpy as np

buffer_size = 32

rb = ReplayBuffer(buffer_size,{"obs": {"shape": (4,4)},
                               "act": {"shape": 1},
                               "rew": {},
                               "next_obs": {"shape": (4,4)},
                               "next_next_obs": {"shape": (4,4)},
                               "done": {},
                               "my_important_info": {"dtype": {np.short}}})

rb.add(obs=np.zeros((4,4)),
       act=1.5,
       rew=0.0,
       next_obs=np.zeros((4,4)),
       next_next_obs=np.zeros((4,4)),
       done=0,
       my_important_info=2)
#+end_src
*** Notes
~priorities~, ~weights~, and ~indexes~ for ~PrioritizedReplayBuffer~
are special environments and are automatically set.


*** Technical Detail
Internally, these flexible environments are implemented with (cython
version of) ~numpy.ndarray~. They were implemented with C++ code in
older than version 8, which had trouble in flexibilities of data type
and the number of environment. (There was a dirty hack to put all
extra environments into ~act~ which was not treat specially.)


** TODO Memory Compression
:PROPERTIES:
:EXPORT_FILE_NAME: memory_compression
:END:

Since replay buffer stores a large number of data set, memory
efficiency is one of the most important point.

In cpprb, there are two functionalities named ~next_of~ and
~stack_compress~, which you can turn on manually when constructing
replay buffer.

~next_of~ and ~stack_compress~ can be used together, but currently
none of them are compatible with N-step replay buffer.


*** ~next_of~

**** Overview
In reinforcement learning, usually a set of observations before and
after a certain action are used for training, so that you save the set
in your replay buffer together. Naively speaking, all observations are
stored twice.

As you know, replay buffer is a ring buffer and the next value should
be stored at next index, except for the newest edge.

If you specify ~next_of~ argument (its type is ~str~ or array like of
~str~), the "next value" of specified values are also set in the
replay buffer and they share the memory location.

The name of the next value adds prefix ~next_~ to the original name
(e.g. ~next_obs~ for ~obs~, ~next_rew~ for ~rew~, and so on).

This functionality has small penalties for manipulating sampled index
and checking the cache for the newest index. (As far as I know, this
penalty is not significant, and you might not notice.)

**** Example Usage
#+begin_src python
from cpprb import ReplayBuffer

buffer_size = 256

rb = ReplayBuffer(buffer_size,{"obs": {"shape": (84,84)},
                               "act": {"shape": 3},
                               "rew": {},
                               "done": {}},
                  next_of=("obs","rew"))

rb.add(obs=np.ones((84,84)),
       act=np.ones(3),
       next_obs=np.ones((84,84)),
       rew=1,
       next_rew=1,
       done=0)
#+end_src

**** Notes
cpprb does not check the consistance of i-th ~next_foo~ and (i+1)-th
~foo~. This is user responsibility.


**** Technical Detail
Internally, ~next_foo~ is not stored into a ring buffer, but into its chache.
(So still raising error if you don't pass them to ~add~.)

When sampling, indices (which is ~numpy.ndarray~) are shifted (and
wraparounded if necessary), then are checked whether they are on the
newest edge of the ring buffer.

*** ~stack_compress~

**** Overview
~stack_compress~ is designed for compressing stacked (or sliding
windowed) observation. A famous use case is Atari video game, where 4
frames of display window are treated as single observation and the
next observation is the one slided by only 1 frame. For this example,
a straight forward approach stores all the frames 4 times.

cpprb stores such stacked observation like non stacked observation
(except for the end edge of the ring buffer) by utilizing numpy
sliding trick.

**** Sample Usage

**** Notes

**** Technical Detail
Technically speaking ~numpy.ndarray~ (and other data type supporting
buffer protocol) has properties of item data type, the number of
dimensions, length of each dimension, memory step size of each
dimension, and so on. Usually, no data should overlap memory address,
however, ~stack_compress~ intentionally overlaps the memory addresses
in the stacked dimension.

** TODO Multi-Processing
:PROPERTIES:
:EXPORT_FILE_NAME: multiprocessing
:END:

#+begin_example
WARNING: Multi-Processing is beta feature. This might be buggy, and its API can be changed without notice.
#+end_example

*** Overview
To speed up your exploration task, you might want to run multiple
workers for a single replay buffer simultanaously. ~cpprb~ has special
classes named ~ProcessSharedReplayBuffer~ and
~ProcessSharedPrioritizedReplayBuffer~ to manage such parallel execution.

These classes utilize shared memories allocated by
~multiprocessing.shraredctypes.RawArray~ ([[https://docs.python.org/3/library/multiprocessing.html#multiprocessing.sharedctypes.RawArray][link]]), and provide the same
API as ~ReplayBuffer~ and ~PrioritizedReplayBuffer~, respectively,
except an additional initialization in child processes.

*** User Responsibility
~cpprb~ takes care of ~add~-ing from multple processing simultanaouly,
however, *don't* consider of ~sample~-ing or ~clear~-ing.

User *must* wait until all sub-processes finish ~add~-ing before call
~sample~ or ~clear~.

*** Example Usage

#+begin_src python
import multiprocessing as mp
from cpprb import ProcessSharedReplayBuffer

buffer_size = 1024
obs_dim = 3
act_dim = 1

psrb = ProcessSharedReplayBuffer(buffer_size,obs_dim,act_dim)

def woker():
    rb = psrb.init_worker() # Here we re-set shared memory addresses

    ...

    rb.add( ... )

q = [mp.Process(target=worker) for _ in range(8)]
for qe in q:
    qe.start()

for qe in q:
    qe.wait()

batch_size = 256
psrb.sample(batch_size)
#+end_src

*** Technical Detail

**** Process Shared Values
We allocate shared memories by using
~multiprocessing.sharedctypes.RawArray~ (internally ~mmap~ is used),
then create [[https://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html][typed memory views]] of them, and pass their addresses to
C++.

The (virtual) addresses of the shared memories can be different in
each process, so that we recreate replay buffer (thin interface of
shared memories) in ~init_worker~.

**** Lockless Access Contorol
Some values such as ~next_index~ require access control to avoid data
race and thay are performance critical (usual lock guard semantic is
quite expensive), so that we cast their pointers into pointers to
proper ~std::atomic~ type (e.g. ~std::atomic<std::size_t>~).

Fortunately, the size of ~std::atomic<T>~ is equal to that of ~T~, as
long as we checked. (We haven't fully confirmed yet.)

