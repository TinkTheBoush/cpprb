#+OPTIONS: ':nil -:nil ^:{} num:nil toc:nil
#+AUTHOR: Hiroyuki Yamada
#+CREATOR: Emacs 26.1 (Org mode 9.1.14 + ox-hugo)
#+HUGO_WITH_LOCALE:
#+HUGO_FRONT_MATTER_FORMAT: toml
#+HUGO_LEVEL_OFFSET: 1
#+HUGO_PRESERVE_FILLING:
#+HUGO_DELETE_TRAILING_WS:
#+HUGO_SECTION: .
#+HUGO_BUNDLE:
#+HUGO_BASE_DIR: ./
#+HUGO_CODE_FENCE:
#+HUGO_USE_CODE_FOR_KBD:
#+HUGO_PREFER_HYPHEN_IN_TAGS:
#+HUGO_ALLOW_SPACES_IN_TAGS:
#+HUGO_AUTO_SET_LASTMOD:
#+HUGO_CUSTOM_FRONT_MATTER:
#+HUGO_BLACKFRIDAY:
#+HUGO_FRONT_MATTER_KEY_REPLACE:
#+HUGO_DATE_FORMAT: %Y-%m-%dT%T+09:00
#+HUGO_PAIRED_SHORTCODES:
#+HUGO_PANDOC_CITATIONS:
#+BIBLIOGRAPHY:
#+HUGO_ALIASES:
#+HUGO_AUDIO:
#+DATE: <2019-02-10 Sun>
#+DESCRIPTION:
#+HUGO_DRAFT:
#+HUGO_EXPIRYDATE:
#+HUGO_HEADLESS:
#+HUGO_IMAGES:
#+HUGO_ISCJKLANGUAGE:
#+KEYWORDS:
#+HUGO_LAYOUT:
#+HUGO_LASTMOD:
#+HUGO_LINKTITLE:
#+HUGO_LOCALE:
#+HUGO_MARKUP:
#+HUGO_MENU:
#+HUGO_MENU_OVERRIDE:
#+HUGO_OUTPUTS:
#+HUGO_PUBLISHDATE:
#+HUGO_SERIES:
#+HUGO_SLUG:
#+HUGO_TAGS:
#+HUGO_CATEGORIES:
#+HUGO_RESOURCES:
#+HUGO_TYPE:
#+HUGO_URL:
#+HUGO_VIDEOS:
#+HUGO_WEIGHT: auto

#+STARTUP: showall logdone
* DONE cpprb (C++ Replay Buffer)
CLOSED: [2019-02-10 Sun 20:24]
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_SECTION: .
:END:

** cpprb (C++ Replay Buffer)
~cpprb~ is a python package written by C++. The package provides
replay buffer classes for reinforcement learning.

* Features
:PROPERTIES:
:EXPORT_HUGO_SECTION*: features
:END:

** TODO Flexible Environment
:PROPERTIES:
:EXPORT_FILE_NAME: flexible_environment
:END:

*** Overview

In ~cpprb~ version 8 and newer, you can store any number of
environments (aka. observation, action, etc.).

For example, you can add your special environments like
~next_next_obs~, ~second_reward~, and so on.

These environments can take multi-dimensional shape (e.g. ~3~,
~(4,4)~, ~(84,84,4)~), and any [[https://numpy.org/devdocs/user/basics.types.html][numpy data type]].


In order to construct replay buffers, you need to specify the second
parameter of their constructor, ~env_dict~.

The ~env_dict~ is a ~dict~ whose keys are environment name and whose
values are ~dict~ describing their properties.

The following table is supported properties and their default values.

| key   | description                    | type                         | default value                                    |
|-------+--------------------------------+------------------------------+--------------------------------------------------|
| shape | shape (size of each dimension) | ~int~ or array like of ~int~ | ~1~                                              |
| dtype | data type                      | ~numpy.dtype~                | ~default_dtype~ in constructor or ~numpy.single~ |


*** Example Usage

#+begin_src python
from cpprb import ReplayBuffer
import numpy as np

buffer_size = 32

rb = ReplayBuffer(buffer_size,{"obs": {"shape": (4,4)},
                               "act": {"shape": 1},
                               "rew": {},
                               "next_obs": {"shape": (4,4)},
                               "next_next_obs": {"shape": (4,4)},
                               "done": {},
                               "my_important_info": {"dtype": {np.short}}})

rb.add(obs=np.zeros((4,4)),
       act=1.5,
       rew=0.0,
       next_obs=np.zeros((4,4)),
       next_next_obs=np.zeros((4,4)),
       done=0,
       my_important_info=2)
#+end_src
*** Technical Detail

*** Notes

** TODO Memory Compression
:PROPERTIES:
:EXPORT_FILE_NAME: memory_compression
:END:

** TODO Multi-Processing
:PROPERTIES:
:EXPORT_FILE_NAME: multiprocessing
:END:

#+begin_example
WARNING: Multi-Processing is beta feature. This might be buggy, and its API can be changed without notice.
#+end_example

*** Overview
To speed up your exploration task, you might want to run multiple
workers for a single replay buffer simultanaously. ~cpprb~ has special
classes named ~ProcessSharedReplayBuffer~ and
~ProcessSharedPrioritizedReplayBuffer~ to manage such parallel execution.

These classes utilize shared memories allocated by
~multiprocessing.shraredctypes.RawArray~ ([[https://docs.python.org/3/library/multiprocessing.html#multiprocessing.sharedctypes.RawArray][link]]), and provide the same
API as ~ReplayBuffer~ and ~PrioritizedReplayBuffer~, respectively,
except an additional initialization in child processes.

*** User Responsibility
~cpprb~ takes care of ~add~-ing from multple processing simultanaouly,
however, *don't* consider of ~sample~-ing or ~clear~-ing.

User *must* wait until all sub-processes finish ~add~-ing before call
~sample~ or ~clear~.

*** Example Usage

#+begin_src python
import multiprocessing as mp
from cpprb import ProcessSharedReplayBuffer

buffer_size = 1024
obs_dim = 3
act_dim = 1

psrb = ProcessSharedReplayBuffer(buffer_size,obs_dim,act_dim)

def woker():
    rb = psrb.init_worker() # Here we re-set shared memory addresses

    ...

    rb.add( ... )

q = [mp.Process(target=worker) for _ in range(8)]
for qe in q:
    qe.start()

for qe in q:
    qe.wait()

batch_size = 256
psrb.sample(batch_size)
#+end_src

*** Technical Detail

**** Process Shared Values
We allocate shared memories by using
~multiprocessing.sharedctypes.RawArray~ (internally ~mmap~ is used),
then create [[https://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html][typed memory views]] of them, and pass their addresses to
C++.

The (virtual) addresses of the shared memories can be different in
each process, so that we recreate replay buffer (thin interface of
shared memories) in ~init_worker~.

**** Lockless Access Contorol
Some values such as ~next_index~ require access control to avoid data
race and thay are performance critical (usual lock guard semantic is
quite expensive), so that we cast their pointers into pointers to
proper ~std::atomic~ type (e.g. ~std::atomic<std::size_t>~).

Fortunately, the size of ~std::atomic<T>~ is equal to that of ~T~, as
long as we checked. (We haven't fully confirmed yet.)

